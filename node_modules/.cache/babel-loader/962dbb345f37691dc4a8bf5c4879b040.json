{"ast":null,"code":"var _jsxFileName = \"/mnt/001A831F1A831138/D/Tensorflow-JS/Hand_gesture_fingerpose/Hand_gesture_app/src/App.js\",\n    _s = $RefreshSig$();\n\n// 1. Install Dependencies\n// 2. Import Libraries\n// 3. Setup webcam and canvas\n// 4. Define references to those\n// 5. Load handpose\n// 6. Detect function\n// 7. Drawing utilities from tensorflow\n// 8. Draw functions\n// For Hand Gesture\n// 1. Install Fingerpose npm install fingerpose\n// 2. Add Use state\n// 3. Import emojis and fingerpose import * as fp from \"fingerpose\";\n// 4. Update detect function for gesture handling\n// 5. Setup hook and emoji object \n// 6. Add emoji display to the screen\nimport React, { useRef, useState } from 'react';\nimport * as tf from \"@tensorflow/tfjs\";\nimport * as handpose from '@tensorflow-models/handpose';\nimport Webcam from 'react-webcam';\nimport { drawHand } from \"./utilities\"; //import logo from './logo.svg';\n\nimport './App.css';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nfunction App() {\n  _s();\n\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null);\n  const [emoji, setEmoji] = useState(null);\n  const images = {\n    thumbs_up: thumbs_up,\n    victory: victory\n  };\n\n  const runHandpose = async () => {\n    const net = await handpose.load();\n    console.log(\"Handpose model loaded.\"); //  Loop and detect hands\n\n    setInterval(() => {\n      detect(net);\n    }, 100);\n  };\n\n  const detect = async net => {\n    // Check data is available\n    if (typeof webcamRef.current !== \"undefined\" && webcamRef.current !== null && webcamRef.current.video.readyState === 4) {\n      // Get Video Properties\n      const video = webcamRef.current.video;\n      const videoWidth = webcamRef.current.video.videoWidth;\n      const videoHeight = webcamRef.current.video.videoHeight; // Set video width\n\n      webcamRef.current.video.width = videoWidth;\n      webcamRef.current.video.height = videoHeight; // Set canvas height and width\n\n      canvasRef.current.width = videoWidth;\n      canvasRef.current.height = videoHeight; // Make Detections\n\n      const hand = await net.estimateHands(video);\n      console.log(hand); //Gesture\n\n      if (hand.length > 0) {\n        const GE = new fp.GestureEstimator([fp.Gestures.VictoryGesture, fp.Gestures.ThumbsUpGesture]);\n        const gesture = await GE.estimate(hand[0].landmarks, 8);\n        console.log(gesture);\n\n        if (gesture.gestures !== undefined && gesture.gestures.length > 0) {\n          // console.log(gesture.gestures);\n          const confidence = gesture.gestures.map(prediction => prediction.confidence);\n          const maxConfidence = confidence.indexOf(Math.max.apply(null, confidence)); // console.log(gesture.gestures[maxConfidence].name);\n\n          setEmoji(gesture.gestures[maxConfidence].name);\n          console.log(emoji);\n        }\n      } // Draw mesh\n\n\n      const ctx = canvasRef.current.getContext(\"2d\");\n      drawHand(hand, ctx);\n    }\n  };\n\n  runHandpose();\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"App\",\n    children: /*#__PURE__*/_jsxDEV(\"header\", {\n      className: \"App-header\",\n      children: [/*#__PURE__*/_jsxDEV(Webcam, {\n        ref: webcamRef,\n        style: {\n          position: \"absolute\",\n          marginLeft: \"auto\",\n          marginRight: \"auto\",\n          left: 0,\n          right: 0,\n          textAlign: \"center\",\n          zindex: 9,\n          width: 640,\n          height: 480\n        }\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 105,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"canvas\", {\n        ref: canvasRef,\n        style: {\n          position: \"absolute\",\n          marginLeft: \"auto\",\n          marginRight: \"auto\",\n          left: 0,\n          right: 0,\n          textAlign: \"center\",\n          zindex: 9,\n          width: 640,\n          height: 480\n        }\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 120,\n        columnNumber: 9\n      }, this), emoji !== null ? /*#__PURE__*/_jsxDEV(\"img\", {\n        src: images[emoji],\n        style: {\n          position: \"absolute\",\n          marginLeft: \"auto\",\n          marginRight: \"auto\",\n          left: 400,\n          bottom: 500,\n          right: 0,\n          textAlign: \"center\",\n          height: 100\n        }\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 136,\n        columnNumber: 11\n      }, this) : \"\"]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 104,\n      columnNumber: 7\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 103,\n    columnNumber: 5\n  }, this);\n}\n\n_s(App, \"tG1M9HNhAEPxaO6n/HZ5OlGsIFc=\");\n\n_c = App;\nexport default App;\n\nvar _c;\n\n$RefreshReg$(_c, \"App\");","map":{"version":3,"sources":["/mnt/001A831F1A831138/D/Tensorflow-JS/Hand_gesture_fingerpose/Hand_gesture_app/src/App.js"],"names":["React","useRef","useState","tf","handpose","Webcam","drawHand","App","webcamRef","canvasRef","emoji","setEmoji","images","thumbs_up","victory","runHandpose","net","load","console","log","setInterval","detect","current","video","readyState","videoWidth","videoHeight","width","height","hand","estimateHands","length","GE","fp","GestureEstimator","Gestures","VictoryGesture","ThumbsUpGesture","gesture","estimate","landmarks","gestures","undefined","confidence","map","prediction","maxConfidence","indexOf","Math","max","apply","name","ctx","getContext","position","marginLeft","marginRight","left","right","textAlign","zindex","bottom"],"mappings":";;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA,OAAOA,KAAP,IAAeC,MAAf,EAAsBC,QAAtB,QAAqC,OAArC;AACA,OAAO,KAAKC,EAAZ,MAAoB,kBAApB;AACA,OAAO,KAAKC,QAAZ,MAA0B,6BAA1B;AACA,OAAOC,MAAP,MAAmB,cAAnB;AAEA,SAASC,QAAT,QAAyB,aAAzB,C,CACA;;AACA,OAAO,WAAP;;;AAEA,SAASC,GAAT,GAAe;AAAA;;AACb,QAAMC,SAAS,GAAGP,MAAM,CAAC,IAAD,CAAxB;AACA,QAAMQ,SAAS,GAAGR,MAAM,CAAC,IAAD,CAAxB;AAEA,QAAM,CAACS,KAAD,EAAQC,QAAR,IAAoBT,QAAQ,CAAC,IAAD,CAAlC;AACA,QAAMU,MAAM,GAAG;AAACC,IAAAA,SAAS,EAACA,SAAX;AAAsBC,IAAAA,OAAO,EAACA;AAA9B,GAAf;;AAEA,QAAMC,WAAW,GAAG,YAAY;AAC9B,UAAMC,GAAG,GAAG,MAAMZ,QAAQ,CAACa,IAAT,EAAlB;AACAC,IAAAA,OAAO,CAACC,GAAR,CAAY,wBAAZ,EAF8B,CAG9B;;AACAC,IAAAA,WAAW,CAAC,MAAM;AAChBC,MAAAA,MAAM,CAACL,GAAD,CAAN;AACD,KAFU,EAER,GAFQ,CAAX;AAGD,GAPD;;AASA,QAAMK,MAAM,GAAG,MAAOL,GAAP,IAAe;AAC5B;AACA,QACE,OAAOR,SAAS,CAACc,OAAjB,KAA6B,WAA7B,IACAd,SAAS,CAACc,OAAV,KAAsB,IADtB,IAEAd,SAAS,CAACc,OAAV,CAAkBC,KAAlB,CAAwBC,UAAxB,KAAuC,CAHzC,EAIE;AACA;AACA,YAAMD,KAAK,GAAGf,SAAS,CAACc,OAAV,CAAkBC,KAAhC;AACA,YAAME,UAAU,GAAGjB,SAAS,CAACc,OAAV,CAAkBC,KAAlB,CAAwBE,UAA3C;AACA,YAAMC,WAAW,GAAGlB,SAAS,CAACc,OAAV,CAAkBC,KAAlB,CAAwBG,WAA5C,CAJA,CAMA;;AACAlB,MAAAA,SAAS,CAACc,OAAV,CAAkBC,KAAlB,CAAwBI,KAAxB,GAAgCF,UAAhC;AACAjB,MAAAA,SAAS,CAACc,OAAV,CAAkBC,KAAlB,CAAwBK,MAAxB,GAAiCF,WAAjC,CARA,CAUA;;AACAjB,MAAAA,SAAS,CAACa,OAAV,CAAkBK,KAAlB,GAA0BF,UAA1B;AACAhB,MAAAA,SAAS,CAACa,OAAV,CAAkBM,MAAlB,GAA2BF,WAA3B,CAZA,CAcA;;AACA,YAAMG,IAAI,GAAG,MAAMb,GAAG,CAACc,aAAJ,CAAkBP,KAAlB,CAAnB;AACAL,MAAAA,OAAO,CAACC,GAAR,CAAYU,IAAZ,EAhBA,CAkBA;;AACA,UAAIA,IAAI,CAACE,MAAL,GAAc,CAAlB,EAAqB;AACnB,cAAMC,EAAE,GAAG,IAAIC,EAAE,CAACC,gBAAP,CAAwB,CACjCD,EAAE,CAACE,QAAH,CAAYC,cADqB,EAEjCH,EAAE,CAACE,QAAH,CAAYE,eAFqB,CAAxB,CAAX;AAKA,cAAMC,OAAO,GAAG,MAAMN,EAAE,CAACO,QAAH,CAAYV,IAAI,CAAC,CAAD,CAAJ,CAAQW,SAApB,EAA+B,CAA/B,CAAtB;AACAtB,QAAAA,OAAO,CAACC,GAAR,CAAYmB,OAAZ;;AAEA,YAAIA,OAAO,CAACG,QAAR,KAAqBC,SAArB,IAAkCJ,OAAO,CAACG,QAAR,CAAiBV,MAAjB,GAA0B,CAAhE,EAAmE;AACjE;AAEA,gBAAMY,UAAU,GAAGL,OAAO,CAACG,QAAR,CAAiBG,GAAjB,CAChBC,UAAD,IAAgBA,UAAU,CAACF,UADV,CAAnB;AAGA,gBAAMG,aAAa,GAAGH,UAAU,CAACI,OAAX,CACpBC,IAAI,CAACC,GAAL,CAASC,KAAT,CAAe,IAAf,EAAqBP,UAArB,CADoB,CAAtB,CANiE,CASjE;;AACAhC,UAAAA,QAAQ,CAAC2B,OAAO,CAACG,QAAR,CAAiBK,aAAjB,EAAgCK,IAAjC,CAAR;AACAjC,UAAAA,OAAO,CAACC,GAAR,CAAYT,KAAZ;AACD;AAEF,OA1CD,CA4CA;;;AACA,YAAM0C,GAAG,GAAG3C,SAAS,CAACa,OAAV,CAAkB+B,UAAlB,CAA6B,IAA7B,CAAZ;AACA/C,MAAAA,QAAQ,CAACuB,IAAD,EAAOuB,GAAP,CAAR;AACD;AACF,GAtDD;;AAwDArC,EAAAA,WAAW;AAEX,sBACE;AAAK,IAAA,SAAS,EAAC,KAAf;AAAA,2BACE;AAAQ,MAAA,SAAS,EAAC,YAAlB;AAAA,8BACE,QAAC,MAAD;AACE,QAAA,GAAG,EAAEP,SADP;AAEE,QAAA,KAAK,EAAE;AACL8C,UAAAA,QAAQ,EAAE,UADL;AAELC,UAAAA,UAAU,EAAE,MAFP;AAGLC,UAAAA,WAAW,EAAE,MAHR;AAILC,UAAAA,IAAI,EAAE,CAJD;AAKLC,UAAAA,KAAK,EAAE,CALF;AAMLC,UAAAA,SAAS,EAAE,QANN;AAOLC,UAAAA,MAAM,EAAE,CAPH;AAQLjC,UAAAA,KAAK,EAAE,GARF;AASLC,UAAAA,MAAM,EAAE;AATH;AAFT;AAAA;AAAA;AAAA;AAAA,cADF,eAgBE;AACE,QAAA,GAAG,EAAEnB,SADP;AAEE,QAAA,KAAK,EAAE;AACL6C,UAAAA,QAAQ,EAAE,UADL;AAELC,UAAAA,UAAU,EAAE,MAFP;AAGLC,UAAAA,WAAW,EAAE,MAHR;AAILC,UAAAA,IAAI,EAAE,CAJD;AAKLC,UAAAA,KAAK,EAAE,CALF;AAMLC,UAAAA,SAAS,EAAE,QANN;AAOLC,UAAAA,MAAM,EAAE,CAPH;AAQLjC,UAAAA,KAAK,EAAE,GARF;AASLC,UAAAA,MAAM,EAAE;AATH;AAFT;AAAA;AAAA;AAAA;AAAA,cAhBF,EA+BKlB,KAAK,KAAK,IAAV,gBACD;AACE,QAAA,GAAG,EAAEE,MAAM,CAACF,KAAD,CADb;AAEE,QAAA,KAAK,EAAE;AACL4C,UAAAA,QAAQ,EAAE,UADL;AAELC,UAAAA,UAAU,EAAE,MAFP;AAGLC,UAAAA,WAAW,EAAE,MAHR;AAILC,UAAAA,IAAI,EAAE,GAJD;AAKLI,UAAAA,MAAM,EAAE,GALH;AAMLH,UAAAA,KAAK,EAAE,CANF;AAOLC,UAAAA,SAAS,EAAE,QAPN;AAQL/B,UAAAA,MAAM,EAAE;AARH;AAFT;AAAA;AAAA;AAAA;AAAA,cADC,GAeD,EA9CJ;AAAA;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,UADF;AAsDD;;GAhIQrB,G;;KAAAA,G;AAkIT,eAAeA,GAAf","sourcesContent":["// 1. Install Dependencies\n// 2. Import Libraries\n// 3. Setup webcam and canvas\n// 4. Define references to those\n// 5. Load handpose\n// 6. Detect function\n// 7. Drawing utilities from tensorflow\n// 8. Draw functions\n\n// For Hand Gesture\n// 1. Install Fingerpose npm install fingerpose\n// 2. Add Use state\n// 3. Import emojis and fingerpose import * as fp from \"fingerpose\";\n// 4. Update detect function for gesture handling\n// 5. Setup hook and emoji object \n// 6. Add emoji display to the screen\n\n\nimport React, {useRef,useState} from 'react';\nimport * as tf from \"@tensorflow/tfjs\";\nimport * as handpose from '@tensorflow-models/handpose';\nimport Webcam from 'react-webcam';\n\nimport { drawHand } from \"./utilities\";\n//import logo from './logo.svg';\nimport './App.css';\n\nfunction App() {\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null);\n\n  const [emoji, setEmoji] = useState(null);\n  const images = {thumbs_up:thumbs_up, victory:victory};\n\n  const runHandpose = async () => {\n    const net = await handpose.load();\n    console.log(\"Handpose model loaded.\");\n    //  Loop and detect hands\n    setInterval(() => {\n      detect(net);\n    }, 100);\n  };\n\n  const detect = async (net) => {\n    // Check data is available\n    if (\n      typeof webcamRef.current !== \"undefined\" &&\n      webcamRef.current !== null &&\n      webcamRef.current.video.readyState === 4\n    ) {\n      // Get Video Properties\n      const video = webcamRef.current.video;\n      const videoWidth = webcamRef.current.video.videoWidth;\n      const videoHeight = webcamRef.current.video.videoHeight;\n\n      // Set video width\n      webcamRef.current.video.width = videoWidth;\n      webcamRef.current.video.height = videoHeight;\n\n      // Set canvas height and width\n      canvasRef.current.width = videoWidth;\n      canvasRef.current.height = videoHeight;\n\n      // Make Detections\n      const hand = await net.estimateHands(video);\n      console.log(hand);\n\n      //Gesture\n      if (hand.length > 0) {\n        const GE = new fp.GestureEstimator([\n          fp.Gestures.VictoryGesture,\n          fp.Gestures.ThumbsUpGesture,\n        ]);\n\n        const gesture = await GE.estimate(hand[0].landmarks, 8);\n        console.log(gesture);\n\n        if (gesture.gestures !== undefined && gesture.gestures.length > 0) {\n          // console.log(gesture.gestures);\n\n          const confidence = gesture.gestures.map(\n            (prediction) => prediction.confidence\n          );\n          const maxConfidence = confidence.indexOf(\n            Math.max.apply(null, confidence)\n          );\n          // console.log(gesture.gestures[maxConfidence].name);\n          setEmoji(gesture.gestures[maxConfidence].name);\n          console.log(emoji);\n        }\n\n      }\n\n      // Draw mesh\n      const ctx = canvasRef.current.getContext(\"2d\");\n      drawHand(hand, ctx);\n    }\n  };\n\n  runHandpose();\n\n  return (\n    <div className=\"App\">\n      <header className=\"App-header\">\n        <Webcam\n          ref={webcamRef}\n          style={{\n            position: \"absolute\",\n            marginLeft: \"auto\",\n            marginRight: \"auto\",\n            left: 0,\n            right: 0,\n            textAlign: \"center\",\n            zindex: 9,\n            width: 640,\n            height: 480,\n          }}\n        />\n\n        <canvas\n          ref={canvasRef}\n          style={{\n            position: \"absolute\",\n            marginLeft: \"auto\",\n            marginRight: \"auto\",\n            left: 0,\n            right: 0,\n            textAlign: \"center\",\n            zindex: 9,\n            width: 640,\n            height: 480,\n          }}\n        />\n\n          {emoji !== null ? (\n          <img\n            src={images[emoji]}\n            style={{\n              position: \"absolute\",\n              marginLeft: \"auto\",\n              marginRight: \"auto\",\n              left: 400,\n              bottom: 500,\n              right: 0,\n              textAlign: \"center\",\n              height: 100,\n            }}\n          />\n        ) : (\n          \"\"\n        )}\n\n      </header>\n    </div>\n  );\n}\n\nexport default App;\n"]},"metadata":{},"sourceType":"module"}